# Core training dependencies
torch>=2.2.0
numpy>=1.24.0
pyyaml>=6.0

# Data processing
sentencepiece>=0.2.0

# Model export
onnx>=1.16.0
onnxruntime>=1.18.0
optimum>=1.19.0

# Quantisation (optional)
# auto-gptq>=0.7.0
# autoawq>=0.2.0

# GGUF export (optional, from llama.cpp)
# gguf>=0.1.0
